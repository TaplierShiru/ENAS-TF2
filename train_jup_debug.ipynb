{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "592707dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "import tensorflow as tf\n",
    "\n",
    "# Sometimes TF will spam WARNINGS, in order to shut it - set to print only errors\n",
    "# tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import tensorflow.keras.layers as L\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "from .micro_child import MicroChild\n",
    "from .micro_lstm import MicroLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa41814",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 160 # 160\n",
    "SEED = None\n",
    "\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = load_data()\n",
    "\n",
    "Xtrain = Xtrain / 255\n",
    "Xtest = Xtest / 255\n",
    "\n",
    "Ytrain = Ytrain.astype(np.int32)\n",
    "Ytest = Ytest.astype(np.int32)\n",
    "\n",
    "\n",
    "def pre_process(x, cutout_size=None, seed=None):\n",
    "    x = tf.pad(x, [[4, 4], [4, 4], [0, 0]])\n",
    "    x = tf.image.random_crop(x, [32, 32, 3], seed=seed)\n",
    "    x = tf.image.random_flip_left_right(x, seed=seed)\n",
    "    if cutout_size is not None:\n",
    "        mask = tf.ones([cutout_size, cutout_size], dtype=tf.int32)\n",
    "        start = tf.random_uniform([2], minval=0, maxval=32, dtype=tf.int32)\n",
    "        mask = tf.pad(mask, [[cutout_size + start[0], 32 - start[0]],\n",
    "                           [cutout_size + start[1], 32 - start[1]]])\n",
    "        mask = mask[cutout_size: cutout_size + 32,\n",
    "                  cutout_size: cutout_size + 32]\n",
    "        mask = tf.reshape(mask, [32, 32, 1])\n",
    "        mask = tf.tile(mask, [1, 1, 3])\n",
    "        x = tf.where(tf.equal(mask, 0), x=x, y=tf.zeros_like(x))\n",
    "    return x\n",
    "\n",
    "\n",
    "def data_generator(x_data, y_data, use_preprocess=True):\n",
    "    assert len(x_data) == len(y_data)\n",
    "    x_data, y_data = shuffle(x_data, y_data)\n",
    "    counter = 0\n",
    "    while True:\n",
    "        yield (\n",
    "            pre_process(x_data[counter]) if use_preprocess else x_data[counter], \n",
    "            y_data[counter]\n",
    "        )\n",
    "        counter += 1\n",
    "        if counter == len(x_data):\n",
    "            break\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "     lambda: data_generator(Xtrain, Ytrain),\n",
    "     output_signature=(\n",
    "         tf.TensorSpec(shape=(32, 32, 3), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(1,), dtype=tf.int32)\n",
    "     )\n",
    ")\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "     lambda: data_generator(Xtest, Ytest, use_preprocess=False),\n",
    "     output_signature=(\n",
    "         tf.TensorSpec(shape=(32, 32, 3), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(1,), dtype=tf.int32)\n",
    "     )\n",
    ")\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "iterations_per_epoch = len(Xtrain)//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cbdf298",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_train_dataset = iter(train_dataset)\n",
    "x,y=next(iter_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d17e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_lstm = MicroLSTM(\n",
    "    num_branches=5, num_cells=5, lstm_size=64, # temperature=5.0, \n",
    "    tanh_constant=1.1, entropy_weight=0.0001,\n",
    "    op_tanh_reduce=2.5, decay=0.99\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75565210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nopt_nas = tf.keras.optimizers.Adam(\\n    learning_rate=tf.keras.optimizers.schedules.CosineDecayRestarts(\\n        0.05, first_decay_steps=iterations_per_epoch * 10, \\n        t_mul=2, m_mul=1, alpha=5e-4\\n    ),\\n    beta_1=0.0, epsilon=1e-3\\n)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_nas = tf.keras.optimizers.SGD(\n",
    "    learning_rate=tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "        0.05, first_decay_steps=iterations_per_epoch * 10, \n",
    "        t_mul=2, m_mul=1, alpha=5e-4\n",
    "    ),\n",
    "    momentum=0.9, nesterov=True\n",
    ")\n",
    "\"\"\"\n",
    "opt_nas = tf.keras.optimizers.Adam(\n",
    "    learning_rate=tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "        0.05, first_decay_steps=iterations_per_epoch * 10, \n",
    "        t_mul=2, m_mul=1, alpha=5e-4\n",
    "    ),\n",
    "    beta_1=0.0, epsilon=1e-3\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9ace9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_controller = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0035, \n",
    "    beta_1=0.0, # beta_1=0.0, 0.1 \n",
    "    epsilon=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46489952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MicroNasModel configured to be dynamic-builded. \n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function StackedLayers.__call__ at 0x7f893429d280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function StackedLayers.__call__ at 0x7f893425f700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function CalibrateTwoLayersSize.__call__ at 0x7f892c0aaf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function CalibrateTwoLayersSize.__call__ at 0x7f892c0aaf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function DynamicInputConvBn.__call__ at 0x7f887c045e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function DynamicInputConvBn.__call__ at 0x7f858879d820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Use additional aux-head for training in layer_id=6\n"
     ]
    }
   ],
   "source": [
    "micro_child = MicroChild(\n",
    "    input_shape=(32, 32, 3),\n",
    "    nas_controller=micro_lstm,\n",
    "    opt_nas=opt_nas,\n",
    "    opt_controller=opt_controller,\n",
    "    num_cells=5, num_layers=6, out_filters=20, # 48\n",
    "    keep_prob=0.9, drop_path_keep_prob=0.6,\n",
    "    # l2_reg=1e-4, # TODO: Look at the comment inside this module how to fix it\n",
    "    use_aux_heads=True, clip_mode=ClipGradsMode.NORM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f811f94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/312 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=1/50\n",
      "Train nas-model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/312 [00:21<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Unique_device_/job:localhost/replica:0/task:0/device:GPU:0}} unique expects a 1D vector. [Op:Unique]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-655153a913a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m micro_child.fit_controller(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msteps_per_epoch_for_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_epochs_for_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch_for_controller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5989d59e8300>\u001b[0m in \u001b[0;36mfit_controller\u001b[0;34m(self, data_generator, test_data_generator, steps_per_epoch_for_model, num_epochs_for_model, num_epoch_for_controller, epochs, eval_period)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train nas-model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_nas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs_for_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch_for_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0;31m# Train nas controller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train nas-controller...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5989d59e8300>\u001b[0m in \u001b[0;36mfit_nas\u001b[0;34m(self, data_generator, epochs, steps_per_epoch, print_period, decay)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                     \u001b[0mmetric_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_step_nas_micro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetric_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mmetric_global_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5989d59e8300>\u001b[0m in \u001b[0;36msingle_step_nas_micro\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown clip_mode {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchecked_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchecked_trainable_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;31m# Update metrics (includes the metric that tracks the loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             return tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[1;32m    739\u001b[0m                 functools.partial(\n\u001b[1;32m    740\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribution_strategy_context.get_replica_context().merge_call(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, apply_state, name)\u001b[0m\n\u001b[1;32m    795\u001b[0m                         \u001b[0;32melse\u001b[0m \u001b[0;34m\"update_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                     ):\n\u001b[0;32m--> 797\u001b[0;31m                         update_op = distribution.extended.update(\n\u001b[0m\u001b[1;32m    798\u001b[0m                             \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                             \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2631\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2632\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2633\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2634\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m       return self._replica_ctx_update(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3704\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3706\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3710\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3712\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3713\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3714\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    768\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m                     \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m                 return self._resource_apply_sparse_duplicate_indices(\n\u001b[0m\u001b[1;32m    771\u001b[0m                     \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py\u001b[0m in \u001b[0;36m_resource_apply_sparse_duplicate_indices\u001b[0;34m(self, grad, var, indices, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     ):\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_momentum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             return super()._resource_apply_sparse_duplicate_indices(\n\u001b[0m\u001b[1;32m    174\u001b[0m                 \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_resource_apply_sparse_duplicate_indices\u001b[0;34m(self, grad, handle, indices, **kwargs)\u001b[0m\n\u001b[1;32m   1448\u001b[0m           \u001b[0mAn\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mupdates\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \"\"\"\n\u001b[0;32m-> 1450\u001b[0;31m         summed_grad, unique_indices = _deduplicate_indexed_slices(\n\u001b[0m\u001b[1;32m   1451\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_deduplicate_indexed_slices\u001b[0;34m(values, indices)\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mslices\u001b[0m \u001b[0massociated\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0meach\u001b[0m \u001b[0munique\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0munique_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     summed_values = tf.math.unsorted_segment_sum(\n\u001b[1;32m     69\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index_positions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7207\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7208\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7209\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Unique_device_/job:localhost/replica:0/task:0/device:GPU:0}} unique expects a 1D vector. [Op:Unique]"
     ]
    }
   ],
   "source": [
    "micro_child.fit_controller(\n",
    "    train_dataset, test_dataset, \n",
    "    steps_per_epoch_for_model=iterations_per_epoch,\n",
    "    num_epochs_for_model=1, num_epoch_for_controller=30, \n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcf8050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84b42dba",
   "metadata": {},
   "source": [
    "# Debug stuff\n",
    "Below you can find some stuff for debug created models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03e47133",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cells=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7c2a3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arr = [\n",
    "    # First index - layer_id\n",
    "    [  # Second index - branch id \n",
    "        [ # Third index - prev_cell (id)\n",
    "            [None] * NASLayer.COUNT_OP # Fourth index - op_id\n",
    "        ] * (i + 2)\n",
    "        for i in range(num_cells)\n",
    "    ] * NASCellTypeV1.SIZE\n",
    "] * num_cells\n",
    "len(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8304506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = [None] * num_cells\n",
    "for i in range(num_cells):\n",
    "    test_arr[i] = [  \n",
    "        # Second index - branch id \n",
    "        [ # Third index - prev_cell (id)\n",
    "            [None] * NASLayer.COUNT_OP # Fourth index - op_id\n",
    "        ] * (i + 2)\n",
    "    ] * NASCellTypeV1.SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1204b6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None]]]\n",
      "\n",
      "[[[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]]]\n",
      "\n",
      "[[[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]]]\n",
      "\n",
      "[[[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]]]\n",
      "\n",
      "[[[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for arr in test_arr:\n",
    "    print(arr)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1a1f8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]]]\n",
      "\n",
      "[[[None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]]]\n",
      "\n",
      "[[[None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]]]\n",
      "\n",
      "[[[None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]]]\n",
      "\n",
      "[[[None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]], [[None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None], [None, None, None, None, None]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for arr in test_arr:\n",
    "    print(arr)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74db522b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([None] * num_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc3d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = micro_child.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b22a0f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.enas_layers_dict['0']['normal-layer']._enas_cells_created_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fea8407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " ListWrapper([ListWrapper([<__main__.StackedLayers object at 0x7f46881233d0>, <__main__.StackedLayers object at 0x7f46881072e0>, <__main__.StackedLayers object at 0x7f468812d2b0>, <__main__.StackedLayers object at 0x7f468812da90>, <__main__.StackedLayers object at 0x7f468812d580>]), ListWrapper([<__main__.StackedLayers object at 0x7f46881233d0>, <__main__.StackedLayers object at 0x7f46881072e0>, <__main__.StackedLayers object at 0x7f468812d2b0>, <__main__.StackedLayers object at 0x7f468812da90>, <__main__.StackedLayers object at 0x7f468812d580>]), ListWrapper([<__main__.StackedLayers object at 0x7f46881233d0>, <__main__.StackedLayers object at 0x7f46881072e0>, <__main__.StackedLayers object at 0x7f468812d2b0>, <__main__.StackedLayers object at 0x7f468812da90>, <__main__.StackedLayers object at 0x7f468812d580>]), ListWrapper([<__main__.StackedLayers object at 0x7f46881233d0>, <__main__.StackedLayers object at 0x7f46881072e0>, <__main__.StackedLayers object at 0x7f468812d2b0>, <__main__.StackedLayers object at 0x7f468812da90>, <__main__.StackedLayers object at 0x7f468812d580>]), ListWrapper([<__main__.StackedLayers object at 0x7f46881233d0>, <__main__.StackedLayers object at 0x7f46881072e0>, <__main__.StackedLayers object at 0x7f468812d2b0>, <__main__.StackedLayers object at 0x7f468812da90>, <__main__.StackedLayers object at 0x7f468812d580>])]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_list = model.enas_layers_dict['0']['normal-layer']._enas_cells_created_list[8][0]\n",
    "len(part_list), part_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80646e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, False), (5, False), (5, False), (5, False), (5, False)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(len(p), None in p) for p in part_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dd7b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d23bbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a1be850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.enas_layers_dict['0']['normal-layer']._enas_cells_created_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb331149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " ListWrapper([ListWrapper([<__main__.StackedLayers object at 0x7fd5206d5fa0>, <__main__.StackedLayers object at 0x7fd5206d5040>, <__main__.StackedLayers object at 0x7fd5206d5ca0>, <__main__.StackedLayers object at 0x7fd5206bc7c0>, <__main__.StackedLayers object at 0x7fd5206d5af0>]), ListWrapper([<__main__.StackedLayers object at 0x7fd5206d5fa0>, <__main__.StackedLayers object at 0x7fd5206d5040>, <__main__.StackedLayers object at 0x7fd5206d5ca0>, <__main__.StackedLayers object at 0x7fd5206bc7c0>, <__main__.StackedLayers object at 0x7fd5206d5af0>]), ListWrapper([<__main__.StackedLayers object at 0x7fd5206d5fa0>, <__main__.StackedLayers object at 0x7fd5206d5040>, <__main__.StackedLayers object at 0x7fd5206d5ca0>, <__main__.StackedLayers object at 0x7fd5206bc7c0>, <__main__.StackedLayers object at 0x7fd5206d5af0>]), ListWrapper([<__main__.StackedLayers object at 0x7fd5206d5fa0>, <__main__.StackedLayers object at 0x7fd5206d5040>, <__main__.StackedLayers object at 0x7fd5206d5ca0>, <__main__.StackedLayers object at 0x7fd5206bc7c0>, <__main__.StackedLayers object at 0x7fd5206d5af0>]), ListWrapper([<__main__.StackedLayers object at 0x7fd5206d5fa0>, <__main__.StackedLayers object at 0x7fd5206d5040>, <__main__.StackedLayers object at 0x7fd5206d5ca0>, <__main__.StackedLayers object at 0x7fd5206bc7c0>, <__main__.StackedLayers object at 0x7fd5206d5af0>])]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_list = model.enas_layers_dict['0']['normal-layer']._enas_cells_created_list[8][0]\n",
    "len(part_list), part_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f7b954e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, False), (5, False), (5, False), (5, False), (5, False)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(len(p), None in p) for p in part_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573d362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c43d884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd028941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_lstm.baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b897a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f6ef47e10edf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m y_pred, y_aux_pred_list = micro_child.model(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mnormal_arc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormal_arc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_arc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_arc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )  # Forward pass\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_input' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred, y_aux_pred_list = micro_child.model(\n",
    "    x_input, \n",
    "    normal_arc=normal_arc, reduce_arc=reduce_arc, \n",
    "    training=True\n",
    ")  # Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f323daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.argmax(y_pred, axis=-1, output_type=tf.int32)\n",
    "reward = tf.equal(y_true, predictions)\n",
    "reward = tf.reduce_mean(tf.cast(reward, dtype=tf.float32))\n",
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda7f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_entropy, sample_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641efbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_lstm.calculate_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7a86753",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(iter_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "181a0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e45090aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input, y_true = data\n",
    "normal_arc, reduce_arc = None, None\n",
    "if micro_child.fixed_arc is None:\n",
    "    (normal_arc, reduce_arc), _, _, _, _ = micro_child.nas_controller.calculate_entropy()\n",
    "else:\n",
    "    # TODO: Parse fixed arc?\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bc13f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(nan, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.5360575>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    y_pred, y_aux_pred_list = micro_child.model(\n",
    "        x_input, \n",
    "        normal_arc=normal_arc, reduce_arc=reduce_arc, \n",
    "        training=True\n",
    "    )  # Forward pass\n",
    "    # Compute the loss value\n",
    "    # (the loss function is configured in `compile()`)\n",
    "    losses = micro_child.model.losses\n",
    "    print(tf.reduce_mean(losses))\n",
    "    loss = micro_child.model.compiled_loss(y_true, y_pred, regularization_losses=losses)\n",
    "    if y_aux_pred_list is not None and len(y_aux_pred_list) > 0:\n",
    "        aux_loss = 0.0\n",
    "        for y_aux_head_s in y_aux_pred_list:\n",
    "            aux_loss += micro_child.model.compiled_loss(y_true, y_aux_head_s)\n",
    "        loss += micro_child.model.aux_scale * aux_loss\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4bb95ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute gradients\n",
    "gradients = tape.gradient(loss, micro_child.model.trainable_variables)\n",
    "# Remove gradients which are None aka not used with current normal/reduce arc\n",
    "checked_gradients = []\n",
    "checked_trainable_vars = []\n",
    "for gr, tr_var in zip(gradients, micro_child.model.trainable_variables):\n",
    "    # TODO: Is `gr` also None then using tf.function for layers? Need to test it!\n",
    "    if gr is not None:\n",
    "        if micro_child.clip_mode is not None and micro_child.clip_mode == ClipGradsMode.NORM:\n",
    "            assert micro_child.grad_bound_nas_model, \"Need grad_bound to clip gradients.\"\n",
    "            # TODO: Is this if-else needed?\n",
    "            if isinstance(gr, tf.IndexedSlices):\n",
    "                c_g = tf.clip_by_norm(gr.values, micro_child.grad_bound_nas_model)\n",
    "                c_g = tf.IndexedSlices(gr.indices, c_g, dense_shape=tf.shape(tr_var))\n",
    "            else:\n",
    "                c_g = tf.clip_by_norm(gr, micro_child.grad_bound_nas_model)\n",
    "            gr = c_g\n",
    "        checked_gradients.append(gr)\n",
    "        checked_trainable_vars.append(tr_var)\n",
    "# TODO: Test it!\n",
    "if micro_child.clip_mode is not None:\n",
    "    assert micro_child.grad_bound_nas_model, \"Need grad_bound to clip gradients.\"\n",
    "    if micro_child.clip_mode == ClipGradsMode.GLOBAL:\n",
    "        checked_gradients, _ = tf.clip_by_global_norm(checked_gradients, micro_child.grad_bound_nas_model)\n",
    "    elif micro_child.clip_mode == ClipGradsMode.NORM:\n",
    "        # Applied above\n",
    "        pass\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown clip_mode {}\".format(self.clip_mode))\n",
    "len(checked_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f503757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(TensorShape([60]), TensorShape([60])),\n",
       " (TensorShape([60]), TensorShape([60])),\n",
       " (TensorShape([3, 3, 3, 60]), TensorShape([3, 3, 3, 60])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([3, 3, 20, 1]), TensorShape([3, 3, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([3, 3, 20, 1]), TensorShape([3, 3, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([3, 3, 20, 1]), TensorShape([3, 3, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([3, 3, 20, 1]), TensorShape([3, 3, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([5, 5, 20, 1]), TensorShape([5, 5, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([5, 5, 20, 1]), TensorShape([5, 5, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([5, 5, 20, 1]), TensorShape([5, 5, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([5, 5, 20, 1]), TensorShape([5, 5, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([3, 3, 20, 1]), TensorShape([3, 3, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([3, 3, 20, 1]), TensorShape([3, 3, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([5, 5, 20, 1]), TensorShape([5, 5, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([5, 5, 20, 1]), TensorShape([5, 5, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([1, 1, 60, 20]), TensorShape([1, 1, 60, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([1, 1, 60, 20]), TensorShape([1, 1, 60, 20])),\n",
       " (TensorShape([7, 400]), TensorShape([7, 400])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([3, 3, 20, 1]), TensorShape([3, 3, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([3, 3, 20, 1]), TensorShape([3, 3, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([3, 3, 20, 1]), TensorShape([3, 3, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([3, 3, 20, 1]), TensorShape([3, 3, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([5, 5, 20, 1]), TensorShape([5, 5, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([5, 5, 20, 1]), TensorShape([5, 5, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([5, 5, 20, 1]), TensorShape([5, 5, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([5, 5, 20, 1]), TensorShape([5, 5, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([3, 3, 20, 1]), TensorShape([3, 3, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([3, 3, 20, 1]), TensorShape([3, 3, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([5, 5, 20, 1]), TensorShape([5, 5, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([5, 5, 20, 1]), TensorShape([5, 5, 20, 1])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([1, 1, 60, 20]), TensorShape([1, 1, 60, 20])),\n",
       " (TensorShape([7, 400]), TensorShape([7, 400])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([20]), TensorShape([20])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([7, 1600]), TensorShape([7, 1600])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([1, 1, 20, 20]), TensorShape([1, 1, 20, 20])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([7, 1600]), TensorShape([7, 1600])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([3, 3, 40, 1]), TensorShape([3, 3, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([5, 5, 40, 1]), TensorShape([5, 5, 40, 1])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([7, 1600]), TensorShape([7, 1600])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([40]), TensorShape([40])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([7, 6400]), TensorShape([7, 6400])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([1, 1, 40, 40]), TensorShape([1, 1, 40, 40])),\n",
       " (TensorShape([768]), TensorShape([768])),\n",
       " (TensorShape([768]), TensorShape([768])),\n",
       " (TensorShape([1, 1, 128, 768]), TensorShape([1, 1, 128, 768])),\n",
       " (TensorShape([768, 10]), TensorShape([768, 10])),\n",
       " (TensorShape([128]), TensorShape([128])),\n",
       " (TensorShape([128]), TensorShape([128])),\n",
       " (TensorShape([1, 1, 80, 128]), TensorShape([1, 1, 80, 128])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([7, 6400]), TensorShape([7, 6400])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([3, 3, 80, 1]), TensorShape([3, 3, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([5, 5, 80, 1]), TensorShape([5, 5, 80, 1])),\n",
       " (TensorShape([1, 1, 80, 80]), TensorShape([1, 1, 80, 80])),\n",
       " (TensorShape([7, 6400]), TensorShape([7, 6400])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80]), TensorShape([80])),\n",
       " (TensorShape([80, 10]), TensorShape([80, 10]))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(ch_g.shape, v.shape) for ch_g, v in zip(checked_gradients, checked_trainable_vars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58308b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients[2] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14850496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e90d9fe6bbf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_v\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-e90d9fe6bbf0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_v\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "[(float(tf.reduce_mean(g).numpy()), t_v.name) for g, t_v in zip(gradients, trainable_vars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "663c172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -9.277481149183586e-05 dynamic_inputs_conv/kernel:0\n",
      "1 -2.073124051094055e-06 dynamic_inputs_bn/gamma:0\n",
      "2 0.002038371516391635 dynamic_inputs_bn/beta:0\n",
      "3 -0.00037956019514240324 dynamic_inputs_conv/kernel:0\n",
      "4 -1.4942139614504413e-06 dynamic_inputs_bn/gamma:0\n",
      "5 3.9041043464749237e-07 dynamic_inputs_bn/beta:0\n",
      "6 -5.117017281008884e-05 dynamic_inputs_conv/kernel:0\n",
      "7 2.9209162676124834e-05 dynamic_inputs_bn/gamma:0\n",
      "8 0.0010020241606980562 dynamic_inputs_bn/beta:0\n",
      "9 -1.6010528270271607e-05 dynamic_inputs_conv/kernel:0\n",
      "10 8.332589459314477e-06 dynamic_inputs_bn/gamma:0\n",
      "11 0.0005863040569238365 dynamic_inputs_bn/beta:0\n",
      "12 1.0485095117473975e-05 dynamic_inputs_conv/kernel:0\n",
      "13 -4.3222681256338547e-07 dynamic_inputs_bn/gamma:0\n",
      "14 1.4901161193847656e-07 dynamic_inputs_bn/beta:0\n",
      "15 -2.612958269310184e-06 dynamic_inputs_conv/kernel:0\n",
      "16 1.4242134056985378e-05 dynamic_inputs_bn/gamma:0\n",
      "17 0.00016833438712637872 dynamic_inputs_bn/beta:0\n",
      "18 1.639735046410351e-06 dynamic_inputs_conv/kernel:0\n",
      "19 -4.4026878640579525e-06 dynamic_inputs_bn/gamma:0\n",
      "20 2.426831088087056e-05 dynamic_inputs_bn/beta:0\n",
      "21 1.1203374015167356e-05 dynamic_inputs_conv/kernel:0\n",
      "22 0.004455194342881441 dynamic_inputs_bn/gamma:0\n",
      "23 0.004460555501282215 dynamic_inputs_bn/beta:0\n"
     ]
    }
   ],
   "source": [
    "found_g = []\n",
    "for g, t_v in zip(gradients, trainable_vars):\n",
    "    if 'dynamic_inputs_' in t_v.name:\n",
    "        print(len(found_g), float(tf.reduce_mean(g).numpy()), t_v.name)\n",
    "        found_g.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33194648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "87840d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for bn\n",
    "g_ex = found_g[22]\n",
    "\n",
    "_ = sns.histplot(g_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47e9acdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7, 1, 1, 80, 80])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for conv\n",
    "g_ex = found_g[21]\n",
    "shape = tf.shape(g_ex)\n",
    "in_f = out_f = tf.cast(tf.sqrt(tf.cast(shape[1], dtype=tf.float32)), dtype=tf.int32)\n",
    "g_ex = tf.reshape(g_ex, (shape[0], 1, 1, in_f, out_f))\n",
    "g_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29727ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure=0, mean=0.0\n",
      "Figure=1, mean=0.0\n",
      "Figure=2, mean=0.0\n",
      "Figure=3, mean=0.0\n",
      "Figure=4, mean=0.0\n",
      "Figure=5, mean=4.2916264646919444e-05\n",
      "Figure=6, mean=3.550735709723085e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "\n",
    "for i in range(7):\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    g_data = g_ex[i].numpy().reshape(-1)\n",
    "    sns.histplot(g_data)\n",
    "    print(f'Figure={i}, mean={g_data.mean()}')\n",
    "    plt.title(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094ff58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60caa277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c89cd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0029549121391028166, -0.00635257363319397)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_mean = np.asarray([float(tf.reduce_mean(g).numpy()) for g, t_v in zip(gradients, trainable_vars)])\n",
    "gr_mean.max(), gr_mean.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99df5cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-3bc923061942>:1: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(gr_mean)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Density'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(gr_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f090ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update weights\n",
    "micro_child.model.optimizer.apply_gradients(zip(gradients, trainable_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd02ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b8b0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_aux_pred_list = micro_child.model(\n",
    "    x_input, \n",
    "    normal_arc=normal_arc, reduce_arc=reduce_arc, \n",
    "    training=True\n",
    ")  # Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dab66c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.7167526>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(micro_child.model.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a62199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25b29d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i1 in range(len(micro_child.model.enas_layers_dict['0']['normal-layer']._enas_cells_created_list)):\n",
    "    l1_list = micro_child.model.enas_layers_dict['0']['normal-layer']._enas_cells_created_list[i1]\n",
    "    for i2 in range(len(l1_list)):\n",
    "        l2_list = l1_list[i2]\n",
    "        for i3 in range(len(l2_list)):\n",
    "            l3_list = l2_list[i3]\n",
    "            for i4 in range(len(l3_list)):\n",
    "                l4_stacked = l3_list[i4]\n",
    "                for layer_i in l4_stacked.layers:\n",
    "                    if isinstance(layer_i, ConvBn):\n",
    "                        print(i1, i2, i3, i4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a692cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c913bb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListWrapper([<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f420281c340>])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_child.model.enas_layers_dict['0']['normal-layer']._enas_cells_created_list[0][0][-2][3].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "163d9ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.separable_conv2d.SeparableConv2D at 0x7f42026bc880>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_child.model.enas_layers_dict['0']['normal-layer']._enas_cells_created_list[0][0][0][0].layers[1].sep_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee8e4248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_child.model.enas_layers_dict['0']['normal-layer']._enas_cells_created_list[0][0][0][0].layers[1].losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87382d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'separable_conv2d_332',\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32',\n",
       " 'filters': 20,\n",
       " 'kernel_size': (5, 5),\n",
       " 'strides': (1, 1),\n",
       " 'padding': 'same',\n",
       " 'data_format': 'channels_last',\n",
       " 'dilation_rate': (1, 1),\n",
       " 'groups': 1,\n",
       " 'activation': 'linear',\n",
       " 'use_bias': False,\n",
       " 'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "  'config': {'seed': None}},\n",
       " 'bias_initializer': None,\n",
       " 'kernel_regularizer': None,\n",
       " 'bias_regularizer': {'class_name': 'L2',\n",
       "  'config': {'l2': 9.999999747378752e-05}},\n",
       " 'activity_regularizer': None,\n",
       " 'kernel_constraint': None,\n",
       " 'bias_constraint': None,\n",
       " 'depth_multiplier': 1,\n",
       " 'depthwise_initializer': {'class_name': 'GlorotUniform',\n",
       "  'config': {'seed': None}},\n",
       " 'pointwise_initializer': {'class_name': 'GlorotUniform',\n",
       "  'config': {'seed': None}},\n",
       " 'depthwise_regularizer': {'class_name': 'L2',\n",
       "  'config': {'l2': 9.999999747378752e-05}},\n",
       " 'pointwise_regularizer': {'class_name': 'L2',\n",
       "  'config': {'l2': 9.999999747378752e-05}},\n",
       " 'depthwise_constraint': None,\n",
       " 'pointwise_constraint': None}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_child.model.enas_layers_dict['0']['normal-layer']._enas_cells_created_list[0][0][0][0].layers[1].sep_conv.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd652d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "351947bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(test_dataset.repeat())\n",
    "accuracy_calc = tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a9c1269",
   "metadata": {},
   "outputs": [],
   "source": [
    "(normal_arc, reduce_arc), _, _ = micro_child.nas_controller.calculate_entropy()\n",
    "\n",
    "x_data, y_data = next(test_iter)\n",
    "predictions, _ = micro_child.model(\n",
    "    x_data, \n",
    "    normal_arc=normal_arc, reduce_arc=reduce_arc, \n",
    "    training=True # TODO: True is right here?\n",
    ")\n",
    "predictions = tf.argmax(predictions, axis=-1)\n",
    "accuracy_calc.reset_state()\n",
    "accuracy_calc.update_state(y_data, predictions)\n",
    "reward = accuracy_calc.result()\n",
    "reward = tf.stop_gradient(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4de25778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.13125>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1e64add",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    loss, reward = micro_child.nas_controller.calculate_loss(reward, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23281ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = tape.gradient(loss, micro_child.nas_controller.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb56a81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01846197247505188, 'b-soft:0'),\n",
       " (5.662335752276704e-05, 'g-emb:0'),\n",
       " (0.00010873021528823301, 'att-v:0'),\n",
       " (-4.0373511183133814e-06, 'att-w-1:0'),\n",
       " (-5.088034438216482e-09, 'att-w-2:0'),\n",
       " (-2.1859452317585237e-05, 'w-emb:0'),\n",
       " (-7.929662388050929e-05, 'w-soft:0'),\n",
       " (-3.0071714718360454e-07, 'lstm/lstm_cell/kernel:0'),\n",
       " (3.378854671609588e-07, 'lstm/lstm_cell/recurrent_kernel:0'),\n",
       " (-6.085422864998691e-05, 'lstm/lstm_cell/bias:0'),\n",
       " (-6.582453693226853e-08, 'lstm_1/lstm_cell_1/kernel:0'),\n",
       " (-6.582453693226853e-08, 'lstm_1/lstm_cell_1/recurrent_kernel:0'),\n",
       " (-7.285163155756891e-05, 'lstm_1/lstm_cell_1/bias:0')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(float(tf.reduce_mean(g).numpy()), v.name) for (g, v) in zip(grads, micro_child.nas_controller.trainable_variables)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34482ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.opt_controller.apply_gradients(zip(grads, self.nas_controller.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1642dc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_calc = tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "720bac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = iter(test_dataset.repeat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ef2e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "(normal_arc, reduce_arc), _, _ = micro_child.nas_controller.calculate_entropy()\n",
    "\n",
    "x_data, y_data = next(data_gen)\n",
    "predictions, _ = micro_child.model(\n",
    "    x_data, \n",
    "    normal_arc=normal_arc, reduce_arc=reduce_arc, \n",
    "    training=True # TODO: True is right here?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d53f3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([160]), TensorShape([160, 1]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tf.argmax(predictions, axis=-1)\n",
    "predictions.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_calc.reset_state()\n",
    "accuracy_calc.update_state(y_data, predictions)\n",
    "reward = accuracy_calc.result()\n",
    "loss, reward = self.single_step_nas_controller(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3f00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24 no-tf-func\n",
    "#  tf-func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "136ebb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "vvv = micro_child.model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b462864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3697"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vvv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4bf138d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.FactorizedReductionLayer at 0x7fce107edeb0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_child.model._get_layer(2, NASLayerType.REDUCTION_LAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ddcf3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListWrapper([2, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_child.model.pool_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "637f5bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(np.load('weights/shared_weights_for_0/0_enascell_x_5.npz'))['w_depthwise'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f783519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac34c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f2a17b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 1, 2, 2, 2, 2, 2, 1, 4], dtype=int32),\n",
       " array([1, 0, 0, 1, 3, 2, 1, 0, 4, 0], dtype=int32))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(normal_arc, reduce_arc), entr, log = micro_lstm.calculate_entropy()\n",
    "normal_arc = normal_arc.numpy()\n",
    "reduce_arc = reduce_arc.numpy()\n",
    "normal_arc[::2], reduce_arc[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd099314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some loss error with this config...\n",
    "normal_arc = [1,1,1,1,1,1,2,0,1,1,2,1,3,0,1,0,4,0,1,0,2,1,5,0]\n",
    "reduce_arc = [1,1,1,0,2,2,0,0,1,4,2,0,2,0,2,0,1,1,2,1,4,1,2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "637c5ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([1, 32, 32, 60]), TensorShape([1, 32, 32, 60])]\n",
      "[TensorShape([1, 32, 32, 60]), TensorShape([1, 32, 32, 60])]\n",
      "[TensorShape([1, 32, 32, 60]), TensorShape([1, 16, 16, 40])]\n",
      "[TensorShape([1, 16, 16, 40]), TensorShape([1, 16, 16, 80])]\n",
      "[TensorShape([1, 16, 16, 80]), TensorShape([1, 16, 16, 120])]\n",
      "[TensorShape([1, 16, 16, 120]), TensorShape([1, 8, 8, 80])]\n",
      "[TensorShape([1, 8, 8, 80]), TensorShape([1, 8, 8, 160])]\n",
      "[TensorShape([1, 8, 8, 160]), TensorShape([1, 8, 8, 240])]\n"
     ]
    }
   ],
   "source": [
    "model = MicroNasModel(\n",
    "    normal_arc=normal_arc, reduce_arc=reduce_arc, data_input_shape=(32, 32, 3), \n",
    "    num_layers=6, \n",
    "    num_cells=5, out_filters=20, \n",
    "    #keep_prob=0.9, \n",
    "    #drop_path_keep_prob=0.6, \n",
    "    global_step=tf.Variable(0, trainable=False),\n",
    "    path_to_store_shared='./weights', use_aux_heads=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e64de02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([160, 10]),\n",
       " TensorShape([160, 32, 32, 3]),\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([ -67.20114 ,  213.165   , -159.1188  ,   47.12942 ,  -53.963524,\n",
       "         -54.65165 ,   36.38561 ,  -60.508736,  -49.553017, -106.116516],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = True\n",
    "out_x, out_aux_head_x = model(x, training=training)\n",
    "out_x.shape, x.shape, out_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "047e8217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Should some variables will be transferred from older optimizer?\n",
    "opt_nas = micro_child.call_create_opt_nas()\n",
    "model.compile(opt_nas, loss=micro_child.loss, metrics='accuracy', run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82e93697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute aug-head loss!\n"
     ]
    }
   ],
   "source": [
    "loss = model.train_step((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f9dccb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "781200a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=95.54731>,\n",
       " 'accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.11875>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "218bb2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([160, 32, 32, 60]),\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([ 5.3995509e-02, -5.7827290e-02, -4.2014830e-02, -3.0631887e-02,\n",
       "        -1.5955178e-04,  6.8952799e-02,  1.3793041e-01,  1.6407149e-01,\n",
       "        -7.6055050e-02,  1.2029748e-01], dtype=float32)>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_x = model.stem_conv(x, training=training)\n",
    "stem_x.shape, stem_x[0, 0, 0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d82576f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [stem_x, stem_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5f32c6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=nan>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal1 = model._get_layer(\n",
    "        0, NASLayerType.NORMAL_LAYER,\n",
    "    )\n",
    "x_t = normal1(layers, training=training)\n",
    "tf.reduce_mean(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "47354056",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_layers = layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8294bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_tensors: List[tf.Tensor] = list(normal1.calibrate_size_layer(\n",
    "    *prev_layers, training=training\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c2d410aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=-0.0013113822>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.015026496>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf.reduce_mean(l_s) for l_s in prev_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4ac7f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "used = []\n",
    "for cell_id in range(normal1.num_cells):\n",
    "    x_id = normal1.arc[4 * cell_id]\n",
    "    x_op = normal1.arc[4 * cell_id + 1]\n",
    "    x = tf.gather(prev_tensors, x_id) # prev_tensors[x_id]\n",
    "    x = normal1._run_enas_cell(\n",
    "        x, cell_id, x_id, x_op, normal1.out_filters, \n",
    "        cell_type=NASCellType.X_TYPE, training=training\n",
    "    )\n",
    "\n",
    "    y_id = normal1.arc[4 * cell_id + 2]\n",
    "    y_op = normal1.arc[4 * cell_id + 3]\n",
    "    y = tf.gather(prev_tensors, y_id) # prev_tensors[y_id]\n",
    "    y = normal1._run_enas_cell(\n",
    "        y, cell_id, y_id, y_op, normal1.out_filters, \n",
    "        cell_type=NASCellType.Y_TYPE, training=training\n",
    "    )\n",
    "\n",
    "    merge_out = x + y\n",
    "    prev_tensors.append(merge_out)\n",
    "\n",
    "    used.extend([\n",
    "        tf.one_hot(x_id, depth=normal1.num_cells + 2, dtype=tf.int32),\n",
    "        tf.one_hot(y_id, depth=normal1.num_cells + 2, dtype=tf.int32)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b57e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "[tf.reduce_mean(l_s) for l_s in prev_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "78c72a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e201f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_id = normal1.arc[4 * cell_id]\n",
    "x_op = normal1.arc[4 * cell_id + 1]\n",
    "x = tf.gather(prev_tensors, x_id) # prev_tensors[x_id]\n",
    "x = normal1._run_enas_cell(\n",
    "    x, cell_id, x_id, x_op, normal1.out_filters, \n",
    "    cell_type=NASCellType.X_TYPE, training=training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f7377edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_created = normal1.get_enas_cell(\n",
    "    cell_id, x_id, NASCellType.X_TYPE, x_op, normal1.out_filters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "085c6ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]],\n",
       " \n",
       " \n",
       "        [[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]],\n",
       " \n",
       " \n",
       "        [[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]],\n",
       " \n",
       " \n",
       "        [[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]],\n",
       " \n",
       " \n",
       "        [[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]],\n",
       " \n",
       "         [[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]]], dtype=float32),\n",
       " array([[[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan]]]], dtype=float32)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_created.layers[1].sep_conv.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "493e9ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=nan>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d55e538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal 0 = nan\n",
      "normal 1 = nan\n",
      "reduction 2 = nan\n",
      "normal 2 = nan\n",
      "normal 3 = nan\n",
      "normal 4 = nan\n",
      "reduction 5 = nan\n",
      "normal 5 = nan\n",
      "normal 6 = nan\n",
      "normal 7 = nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([160, 8, 8, 80]), <tf.Tensor: shape=(), dtype=float32, numpy=nan>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [stem_x, stem_x]\n",
    "\n",
    "aux_result_tensors_list = []\n",
    "for layer_id in range(model.num_layers + 2):\n",
    "    if layer_id in model.pool_layers:\n",
    "        x_t = model._get_layer(\n",
    "            layer_id, NASLayerType.REDUCTION_LAYER,\n",
    "        )(x_t, training=training)\n",
    "        layers = [layers[-1], x_t]\n",
    "        print(f'reduction {layer_id} = {tf.reduce_mean(x_t)}')\n",
    "    x_t = model._get_layer(\n",
    "        layer_id, NASLayerType.NORMAL_LAYER,\n",
    "    )(layers, training=training)\n",
    "    layers = [layers[-1], x_t]\n",
    "    print(f'normal {layer_id} = {tf.reduce_mean(x_t)}')\n",
    "\n",
    "    if model.use_aux_heads and layer_id in model.aux_head_indices and training:\n",
    "        aux_result_tensors_list += [\n",
    "            model._get_layer(\n",
    "                layer_id, NASLayerType.AUX_LAYER\n",
    "            )(x_t, training=training)\n",
    "        ]\n",
    "x_t.shape, tf.reduce_mean(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e13f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20afc917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(160,), dtype=int64, numpy=\n",
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(tf.math.softmax(out_x, axis=-1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1ae8c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_x[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5725bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ac3c4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=nan>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(y, out_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3435245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7994caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_c=None\n",
    "prev_h=None\n",
    "use_bias=False\n",
    "training=False\n",
    "# TODO: Rewrite it to\n",
    "#           https://github.com/google-research/google-research/blob/698c1a53af550cf29becdb08e1c1b2f0a507dd46/enas_lm/src/controller.py#L116\n",
    "# Good example on torch:\n",
    "#           https://github.com/MengTianjian/enas-pytorch/blob/master/micro_controller.py\n",
    "arc_seq, sample_log_probs, sample_entropy = [], [], []\n",
    "all_h = [tf.zeros([1, micro_lstm.lstm_size], dtype=tf.float32)]\n",
    "all_h_w = [tf.zeros([1, micro_lstm.lstm_size], dtype=tf.float32)]\n",
    "inputs = tf.expand_dims(micro_lstm.g_emb, axis=0)\n",
    "for layer_id in range(micro_lstm.num_generated_cells):\n",
    "    _, next_c, next_h = micro_lstm.call_lstm(\n",
    "        inputs, prev_h=prev_h, prev_c=prev_c, training=training\n",
    "    )\n",
    "    prev_c, prev_h = next_c, next_h\n",
    "    all_h.append(tf.zeros_like(next_h)) # next_h or zeros with shape as next_h ???\n",
    "    all_h_w.append(\n",
    "        tf.matmul(next_h, micro_lstm.w_attn_1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41262036",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "028d2029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_id < (micro_lstm.num_cells + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8f173aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Operation\n",
    "_, next_c, next_h = micro_lstm.call_lstm(\n",
    "   inputs, prev_h=prev_h, prev_c=prev_c, training=training\n",
    ")\n",
    "# prev_c, prev_h = next_c, next_h\n",
    "logits = tf.matmul(next_h, micro_lstm.w_soft) + micro_lstm.b_soft\n",
    "if micro_lstm.temperature is not None:\n",
    "    logits /= micro_lstm.temperature\n",
    "if micro_lstm.tanh_constant is not None:\n",
    "    logits = micro_lstm.tanh_constant * tf.tanh(logits)\n",
    "if use_bias:\n",
    "    logits += micro_lstm.b_soft_not_learned\n",
    "op_id = tf.random.categorical(logits, 1)\n",
    "op_id = tf.cast(op_id, dtype=tf.int32)\n",
    "op_id = tf.reshape(op_id, [])\n",
    "op_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b66dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_seq_cell = [None] * 4\n",
    "prev_layers = []\n",
    "for cell_i in range(2):\n",
    "    _, next_c, next_h = micro_lstm.call_lstm(\n",
    "        inputs, prev_h=prev_h, prev_c=prev_c, training=training\n",
    "    )\n",
    "    prev_c, prev_h = next_c, next_h\n",
    "    query = tf.tanh(\n",
    "        tf.concat(all_h_w[:layer_id], axis=0) + tf.matmul(next_h, micro_lstm.w_attn_2)\n",
    "    )\n",
    "    logits = tf.matmul(query, micro_lstm.v_attn)\n",
    "    logits = tf.reshape(logits, [1, layer_id])\n",
    "    if micro_lstm.temperature is not None:\n",
    "        logits /= micro_lstm.temperature\n",
    "    if micro_lstm.tanh_constant is not None:\n",
    "        logits = micro_lstm.tanh_constant * tf.tanh(logits)\n",
    "\n",
    "    skip_index = tf.random.categorical(logits, 1)\n",
    "    skip_index = tf.cast(skip_index, dtype=tf.int32)\n",
    "    skip_index = tf.reshape(skip_index, [])\n",
    "    arc_seq_cell[cell_i * 2] = skip_index\n",
    "\n",
    "    log_prob = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=tf.reshape(skip_index, [1])\n",
    "    )\n",
    "    sample_log_probs.append(log_prob)\n",
    "\n",
    "    entropy = log_prob * tf.exp(-log_prob)\n",
    "    sample_entropy.append(entropy)\n",
    "\n",
    "    prev_layers.append(all_h[skip_index])\n",
    "    inputs = tf.expand_dims(prev_layers[-1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a5383e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
       " None,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=3>,\n",
       " None]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_seq_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ba026a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for op_i in range(2):\n",
    "    # Operation\n",
    "    _, next_c, next_h = micro_lstm.call_lstm(\n",
    "       inputs, prev_h=prev_h, prev_c=prev_c, training=training\n",
    "    )\n",
    "    prev_c, prev_h = next_c, next_h\n",
    "    logits = tf.matmul(next_h, micro_lstm.w_soft) + micro_lstm.b_soft\n",
    "    if micro_lstm.temperature is not None:\n",
    "        logits /= micro_lstm.temperature\n",
    "    if micro_lstm.tanh_constant is not None:\n",
    "        logits = micro_lstm.tanh_constant * tf.tanh(logits)\n",
    "    if use_bias:\n",
    "        logits += micro_lstm.b_soft_not_learned\n",
    "    op_id = tf.random.categorical(logits, 1)\n",
    "    op_id = tf.cast(op_id, dtype=tf.int32)\n",
    "    op_id = tf.reshape(op_id, [])\n",
    "    arc_seq_cell[op_i * 2 + 1] = op_id\n",
    "    log_prob = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=tf.reshape(op_id, [1])\n",
    "    )\n",
    "    sample_log_probs.append(log_prob)\n",
    "    entropy = log_prob * tf.exp(-log_prob)\n",
    "    sample_entropy.append(entropy)\n",
    "    inputs = tf.expand_dims(tf.expand_dims(\n",
    "        tf.nn.embedding_lookup(micro_lstm.w_emb, op_id), \n",
    "        axis=0 ), axis=0\n",
    "    )            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6437bebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=4>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=3>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=0>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_seq_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "382b67c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, next_c, next_h = micro_lstm.call_lstm(\n",
    "    inputs, prev_h=prev_h, prev_c=prev_c, training=training\n",
    ")\n",
    "arc_seq += arc_seq_cell\n",
    "all_h.append(next_h)\n",
    "all_h_w.append(tf.matmul(next_h, micro_lstm.w_attn_1))\n",
    "inputs = tf.expand_dims(micro_lstm.g_emb, axis=0)\n",
    "layer_id +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7cd148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff2cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743e2238",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_child.model(x)\n",
    "micro_child.model.fit(x,y, batch_size=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458fdee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64224962",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, reward = micro_child.single_step_nas_controller(tf.convert_to_tensor(0.62))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_lstm.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbcdae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = tf.random.uniform(shape=(160, 32, 32, 20))\n",
    "ttt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nas_layer = NASLayer(\n",
    "    0, \n",
    "    [0, 0, 0, 1, 2, 0, 2, 1, 2, 1, 3, 1, 3, 1, 4, 1, 3, 1, 0, 1, 0, 0, 4, 0],\n",
    "    128, 6, \n",
    "    [ttt.shape]*2,\n",
    "    micro_child.global_step, mode=NASModelType.NAS_MODE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efcc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = nas_layer([ttt, ttt])\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af449106",
   "metadata": {},
   "outputs": [],
   "source": [
    "(normal_arc, reduce_arc), entr, log_prob = micro_lstm.calculate_entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc70756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nas_layer = NASLayer(\n",
    "    0, \n",
    "    reduce_arc,\n",
    "    20, 6,\n",
    "    [ttt.shape]*2,\n",
    "    micro_child.global_step, mode=NASModelType.NAS_MODE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd6d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = nas_layer([ttt, ttt])\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925aef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961feb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fdec19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "micro_child.model.save('temp', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dedb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872778dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440955cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_lstm.lstm.la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd539ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cae1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938a1107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb2831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5893f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NASLayer_TEST(CheckpointRestoreModule):\n",
    "\n",
    "    COUNT_OP = 5\n",
    "\n",
    "    def __init__(\n",
    "            self, layer_id: int, arc: Optional[list], out_filters: int, \n",
    "            num_cells: int, input_shape_list: List[tuple], global_step: tf.Tensor, \n",
    "            path_to_store_shared: str = None,\n",
    "            mode=NASModelType.FIXED_MODE, drop_path_keep_prob: float=None,\n",
    "            layer_reg=None, kernel_init='glorot_uniform',\n",
    "            num_stack_enas_conv=2): \n",
    "        super().__init__()\n",
    "        self.layer_id = layer_id\n",
    "        self.arc = arc\n",
    "        self.out_filters = out_filters\n",
    "        self.num_cells = num_cells\n",
    "        self.global_step = global_step\n",
    "        self.path_to_store_shared = path_to_store_shared\n",
    "        self.drop_path_keep_prob = drop_path_keep_prob\n",
    "        self.num_stack_enas_conv = num_stack_enas_conv\n",
    "        if arc is None and mode == NASModelType.FIXED_MODE:\n",
    "            print('Mode for NASLyaer is Fixed, but arc is not provided. Swap mode to NAS-mode.')\n",
    "            mode = NASModelType.NAS_MODE\n",
    "        self.mode = mode\n",
    "\n",
    "        self.calibrate_size_layer = None\n",
    "        self.final_module = None\n",
    "        self.base_module = None\n",
    "\n",
    "        self.layer_reg = layer_reg\n",
    "        self.kernel_init = kernel_init\n",
    "\n",
    "        # List of lists of lists...\n",
    "        self._enas_cells_created_list: List[list, List[list, tf.Module]] = [\n",
    "            # First index - layer_id\n",
    "            [  # Second index - branch id \n",
    "                [ # Third index - prev_cell (id)\n",
    "                    [None] * NASLayer.COUNT_OP # Fourth index - op_id\n",
    "                ] * (i + 2)\n",
    "            ] * NASCellTypeV1.SIZE\n",
    "            for i in range(num_cells)\n",
    "        ] * num_cells\n",
    "\n",
    "        random_tensors = [\n",
    "            tf.random.uniform(shape)\n",
    "            for shape in input_shape_list\n",
    "        ]\n",
    "        self.is_builded = False\n",
    "        self._build_layer(random_tensors)\n",
    "\n",
    "    def load_by_parts(self, path_to_checkpoint: str):\n",
    "        # Save separate modules:\n",
    "        #   global_step, final_module, calibrate_size_layer, base_module\n",
    "        try:\n",
    "            tf.train.Checkpoint(\n",
    "                global_step=self.global_step,\n",
    "            ).read(path_to_checkpoint).expect_partial()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('Skip global_step restore')\n",
    "\n",
    "        try:\n",
    "            tf.train.Checkpoint(\n",
    "                final_module=self.final_module,\n",
    "            ).read(path_to_checkpoint).expect_partial()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('Skip final_module restore')\n",
    "\n",
    "        try:\n",
    "            tf.train.Checkpoint(\n",
    "                calibrate_size_layer=self.calibrate_size_layer,\n",
    "            ).read(path_to_checkpoint).expect_partial()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('Skip calibrate_size_layer restore')\n",
    "\n",
    "        if self.base_module is None and self.mode == NASModelType.FIXED_MODE:\n",
    "            raise Exception('Base module is not builded but current mode is fixed.')\n",
    "\n",
    "        if self.base_module is not None:\n",
    "            try:\n",
    "                tf.train.Checkpoint(\n",
    "                    base_module=self.base_module,\n",
    "                ).read(path_to_checkpoint).expect_partial()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('Skip base_module restore')\n",
    "        else:\n",
    "            print('Skip base_module restore')\n",
    "        # TODO: Load weights from shared folder\n",
    "        # Load each layer independent from others. Why doing this?\n",
    "        # While controller will be trained for our NASModel\n",
    "        # different layers with configs will be produced, the main purpose of this lines\n",
    "        # Is to load layers which are compatible with previous in order to stick to plan \"Shared weights\"\n",
    "        # Shared aka these layers will be same, which means will be loaded from previous model\n",
    "        for module_name, enas_cell in self._enas_cells_created_dict.items():\n",
    "            try:\n",
    "                if isinstance(enas_cell, StackedLayers):\n",
    "                    for ii, layer in enumerate(enas_cell.layers):\n",
    "                        try:\n",
    "                            # Load path should be as:\n",
    "                            #   '_enas_cells_created_dict/enas-cell-0-x-0-20/layers/1'\n",
    "                            #   Here 'enas-cell-0-x-0-20' - is `module_name`\n",
    "                            # This load try only for StackedLayers\n",
    "                            tf.train.Checkpoint(\n",
    "                                _enas_cells_created_dict={\n",
    "                                    module_name: { 'layers': { str(ii): layer }}\n",
    "                                }\n",
    "                            ).read(path_to_checkpoint).expect_partial()\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            print(f'Skip layer number equal to {ii} in {module_name} of stacked layers...')\n",
    "                else:\n",
    "                    # Load path should be as:\n",
    "                    #   '_enas_cells_created_dict/enas-cell-0-x-0-20/layer'\n",
    "                    #   Here 'enas-cell-0-x-0-20' - is `module_name`\n",
    "                    tf.train.Checkpoint(\n",
    "                        _enas_cells_created_dict={\n",
    "                            module_name: enas_cell\n",
    "                        }\n",
    "                    ).read(path_to_checkpoint).expect_partial()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('Skip module={module_name}')\n",
    "\n",
    "    def _build_layer(self, prev_layers):\n",
    "        assert len(prev_layers) == 2\n",
    "        if self.is_builded:\n",
    "            raise Exception('Layer is already builded!')\n",
    "        # Answer will be resized two tensors from prev layers\n",
    "        self.calibrate_size_layer = CalibrateTwoLayersSize(\n",
    "            tf.shape(prev_layers[0]), tf.shape(prev_layers[1]), \n",
    "            self.out_filters,\n",
    "            # Additional params for conv/bn\n",
    "            kernel_regularizer=self.layer_reg,bias_regularizer=self.layer_reg,\n",
    "            beta_regularizer=self.layer_reg,gamma_regularizer=self.layer_reg,\n",
    "            kernel_initializer=self.kernel_init,\n",
    "        )\n",
    "        x0, x1 = self.calibrate_size_layer(prev_layers[0], prev_layers[1])\n",
    "        prev_tensors = [x0, x1]\n",
    "\n",
    "        if self.mode == NASModelType.FIXED_MODE:\n",
    "            if self.base_module is None:\n",
    "                self.base_module = StackedLayers([\n",
    "                    ConvBn(\n",
    "                        self.out_filters, (1,1), padding='SAME',\n",
    "                        # Additional params for conv/bn\n",
    "                        kernel_regularizer=self.layer_reg,bias_regularizer=self.layer_reg,\n",
    "                        beta_regularizer=self.layer_reg,gamma_regularizer=self.layer_reg,\n",
    "                        kernel_initializer=self.kernel_init,\n",
    "                    )\n",
    "                ])\n",
    "            # TODO: `prev_tensors[1] =` but its seems like equal change  \n",
    "            prev_tensors[-1] = self.base_module(prev_layers[-1])\n",
    "\n",
    "        used = []\n",
    "        for cell_id in range(self.num_cells):\n",
    "            if self.arc is None and self.mode == NASModelType.NAS_MODE:\n",
    "                x_id, x_op = 0, 0\n",
    "            elif self.arc is not None and self.mode == NASModelType.FIXED_MODE:\n",
    "                x_id = self.arc[4 * cell_id]\n",
    "                x_op = self.arc[4 * cell_id + 1]\n",
    "            else:\n",
    "                # TODO: Give more details\n",
    "                raise Exception('Unknown nas-layer X configuration.')\n",
    "            x = tf.gather(prev_tensors, x_id) # prev_tensors[x_id]\n",
    "            x = self._build_enas_cell(\n",
    "                x, cell_id, x_id, x_op, self.out_filters, \n",
    "                cell_type=NASCellTypeV1.X_TYPE\n",
    "            )\n",
    "\n",
    "            if self.arc is None and self.mode == NASModelType.NAS_MODE:\n",
    "                y_id, y_op = 0, 0\n",
    "            elif self.arc is not None and self.mode == NASModelType.FIXED_MODE:\n",
    "                y_id = self.arc[4 * cell_id + 2]\n",
    "                y_op = self.arc[4 * cell_id + 3]\n",
    "            else:\n",
    "                # TODO: Give more details\n",
    "                raise Exception('Unknown nas-layer Y configuration.')\n",
    "            y = tf.gather(prev_tensors, y_id) # prev_tensors[y_id]\n",
    "            y = self._build_enas_cell(\n",
    "                y, cell_id, y_id, y_op, self.out_filters, \n",
    "                cell_type=NASCellTypeV1.Y_TYPE\n",
    "            )\n",
    "\n",
    "            merge_out = x + y\n",
    "            prev_tensors.append(merge_out)\n",
    "\n",
    "            used.extend([\n",
    "                tf.one_hot(x_id, depth=self.num_cells + 2, dtype=tf.int32),\n",
    "                tf.one_hot(y_id, depth=self.num_cells + 2, dtype=tf.int32)\n",
    "            ])\n",
    "\n",
    "        if self.mode == NASModelType.NAS_MODE:\n",
    "            self.final_module = DynamicInputConvBn(\n",
    "                self.num_cells+2, self.out_filters, \n",
    "                self.out_filters, (1,1), padding='SAME',\n",
    "                # Additional params for conv/bn\n",
    "                kernel_regularizer=self.layer_reg,bias_regularizer=self.layer_reg,\n",
    "                beta_regularizer=self.layer_reg,gamma_regularizer=self.layer_reg,\n",
    "                kernel_initializer=self.kernel_init,\n",
    "            )\n",
    "\n",
    "            # Select layers (outputs) which are not used for skip connection\n",
    "            used = tf.add_n(used)\n",
    "            indices = tf.where(tf.equal(used, 0))\n",
    "            indices = tf.cast(indices, tf.int32)\n",
    "            indices = tf.reshape(indices, [-1])\n",
    "            num_outs = tf.size(indices)\n",
    "            out = tf.stack(prev_tensors, axis=0)\n",
    "            out = tf.gather(out, indices, axis=0)\n",
    "\n",
    "            out = tf.transpose(out, [1, 2, 3, 0, 4])\n",
    "            shape = tf.shape(out)\n",
    "            out = tf.reshape(out, [shape[0], shape[1], shape[2], num_outs * self.out_filters])\n",
    "        self.is_builded = True\n",
    "\n",
    "    def _build_enas_conv(self, curr_cell, prev_cell, filter_size, out_filters, num_possible_inputs):\n",
    "        builded_layers = []\n",
    "        for conv_id in range(self.num_stack_enas_conv):\n",
    "            builded_layers += [\n",
    "                L.ReLU(),\n",
    "                SeparableConvBn(\n",
    "                    out_filters=out_filters, filter_size=filter_size, padding='SAME',\n",
    "                    curr_cell=curr_cell, prev_cell=prev_cell, \n",
    "                    conv_id=conv_id, num_possible_inputs=num_possible_inputs,\n",
    "                    # Additional params for conv/bn\n",
    "                    kernel_regularizer=self.layer_reg,bias_regularizer=self.layer_reg,\n",
    "                    beta_regularizer=self.layer_reg,gamma_regularizer=self.layer_reg,\n",
    "                    kernel_initializer=self.kernel_init,\n",
    "                )\n",
    "            ]\n",
    "        return builded_layers\n",
    "\n",
    "    def _build_enas_cell_by_type(\n",
    "            self, x, curr_cell, prev_cell, \n",
    "            op_id: int, out_filters: int, \n",
    "            num_possible_inputs: int):\n",
    "        builded_layers = None\n",
    "        if op_id == 0:\n",
    "            builded_layers = self._build_enas_conv(\n",
    "                curr_cell=curr_cell, prev_cell=prev_cell, \n",
    "                filter_size=5, out_filters=out_filters, \n",
    "                num_possible_inputs=num_possible_inputs\n",
    "            )   \n",
    "        elif op_id == 1:\n",
    "            builded_layers = self._build_enas_conv(\n",
    "                curr_cell=curr_cell, prev_cell=prev_cell, \n",
    "                filter_size=3, out_filters=out_filters, \n",
    "                num_possible_inputs=num_possible_inputs\n",
    "            )\n",
    "        elif op_id == 2:\n",
    "            builded_layers = [\n",
    "                L.AveragePooling2D((3,3), (1,1), padding='SAME')\n",
    "            ]\n",
    "            if tf.shape(x)[-1] != out_filters:\n",
    "                builded_layers += [\n",
    "                    ConvBn(\n",
    "                        out_filters=out_filters, filter_size=(1,1), padding='SAME',\n",
    "                        curr_cell=curr_cell, prev_cell=prev_cell, \n",
    "                        conv_id=0, num_possible_inputs=num_possible_inputs,\n",
    "                        type_op=op_id,\n",
    "                        # Additional params for conv/bn\n",
    "                        kernel_regularizer=self.layer_reg,bias_regularizer=self.layer_reg,\n",
    "                        beta_regularizer=self.layer_reg,gamma_regularizer=self.layer_reg,\n",
    "                        kernel_initializer=self.kernel_init,\n",
    "                    )\n",
    "                ]\n",
    "        elif op_id == 3:\n",
    "            builded_layers = [\n",
    "                L.MaxPool2D((3,3), (1,1), padding='SAME')\n",
    "            ]\n",
    "            if tf.shape(x)[-1] != out_filters:\n",
    "                builded_layers += [\n",
    "                    ConvBn(\n",
    "                        out_filters=out_filters, filter_size=(1,1), padding='SAME',\n",
    "                        curr_cell=curr_cell, prev_cell=prev_cell, \n",
    "                        conv_id=0, num_possible_inputs=num_possible_inputs,\n",
    "                        type_op=op_id,\n",
    "                        # Additional params for conv/bn\n",
    "                        kernel_regularizer=self.layer_reg,bias_regularizer=self.layer_reg,\n",
    "                        beta_regularizer=self.layer_reg,gamma_regularizer=self.layer_reg,\n",
    "                        kernel_initializer=self.kernel_init,\n",
    "                    )\n",
    "                ]\n",
    "        elif op_id == 4:\n",
    "            builded_layers = []\n",
    "            if tf.shape(x)[-1] != out_filters:\n",
    "                builded_layers += [\n",
    "                    ConvBn(\n",
    "                        out_filters=out_filters, filter_size=(1,1), padding='SAME',\n",
    "                        curr_cell=curr_cell, prev_cell=prev_cell, \n",
    "                        conv_id=0, num_possible_inputs=num_possible_inputs,\n",
    "                        type_op=op_id,\n",
    "                        # Additional params for conv/bn\n",
    "                        kernel_regularizer=self.layer_reg,bias_regularizer=self.layer_reg,\n",
    "                        beta_regularizer=self.layer_reg,gamma_regularizer=self.layer_reg,\n",
    "                        kernel_initializer=self.kernel_init,\n",
    "                    )\n",
    "                ]\n",
    "        if self.mode == NASModelType.FIXED_MODE and \\\n",
    "                op_id != 4 and self.drop_path_keep_prob is not None :\n",
    "            \n",
    "            builded_layers += [\n",
    "                DropPathLayer(\n",
    "                    self.layer_id, self.drop_path_keep_prob, \n",
    "                    self.num_layers, self.global_step\n",
    "                )\n",
    "            ]\n",
    "        \n",
    "        if builded_layers is None:\n",
    "            raise Exception(f'In NAS-Layer `builded_layers` is None with op_id={op_id}')\n",
    "        return StackedLayers(builded_layers)\n",
    "\n",
    "    def _build_enas_cell(\n",
    "            self, x, curr_cell, prev_cell, \n",
    "            op_id: int, out_filters: int, \n",
    "            cell_type: NASCellTypeV1, training=False):\n",
    "        # TODO: Create shared weights for each operation\n",
    "        #       call here, after that build layers itself and load weights from created point\n",
    "        num_possible_inputs = curr_cell + 2\n",
    "        if self.mode == NASModelType.NAS_MODE:\n",
    "            for prev_cell_i in range(num_possible_inputs):\n",
    "                for op_id_s in range(NASLayer.COUNT_OP):\n",
    "                    builded_layers_module_s = self._build_enas_cell_by_type(\n",
    "                        x, curr_cell, prev_cell_i, op_id_s, out_filters, num_possible_inputs\n",
    "                    )\n",
    "                    self._set_enas_cell(builded_layers_module_s, curr_cell, prev_cell, cell_type, op_id_s)\n",
    "        elif self.mode == NASModelType.FIXED_MODE:\n",
    "            builded_layers_module = self._build_enas_cell_by_type(\n",
    "                x, curr_cell, prev_cell, op_id, out_filters, num_possible_inputs\n",
    "            )\n",
    "            self._set_enas_cell(builded_layers_module, curr_cell, prev_cell, cell_type, op_id)\n",
    "        else:\n",
    "            raise Exception('Unknown mode for nas-layer')\n",
    "        return self.get_enas_cell(curr_cell, prev_cell, cell_type, op_id)(\n",
    "            x, training=training\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, prev_layers: List[tf.Tensor], arc=None, training=False):\n",
    "        assert len(prev_layers) == 2 \n",
    "        if arc is None and self.mode == NASModelType.NAS_MODE:\n",
    "            raise Exception(\"Current layer mode is NAS-mode, but arc parameter was not provided to the layer.\")\n",
    "        elif arc is None and self.mode == NASModelType.FIXED_MODE:\n",
    "            arc = self.arc\n",
    "        elif arc is not None and self.mode == NASModelType.FIXED_MODE:\n",
    "            raise Exception(\"Current layer mode is FIXED-mode, but arc parameter was provided to the layer.\")\n",
    "        # Answer will be resized two tensors from prev layers\n",
    "        x0, x1 = self.calibrate_size_layer(\n",
    "            *prev_layers, training=training\n",
    "        )\n",
    "        # TODO: Set size - its known here\n",
    "        prev_tensors = [x0, x1]\n",
    "\n",
    "        if self.mode == NASModelType.FIXED_MODE:\n",
    "            if self.base_module is None:\n",
    "                raise Exception('Base module is not builded but current mode is fixed.')\n",
    "            prev_tensors[-1] = self.base_module(prev_layers[-1], training=training)\n",
    "\n",
    "        used = []\n",
    "        for cell_id in range(self.num_cells):\n",
    "            x_id = arc[4 * cell_id]\n",
    "            x_op = arc[4 * cell_id + 1]\n",
    "            x = tf.gather(prev_tensors, x_id) # prev_tensors[x_id]\n",
    "            x = self.get_enas_cell_tf(\n",
    "                cell_id, x_id, NASCellTypeV1.X_TYPE, x_op,\n",
    "                x, training=training\n",
    "            )\n",
    "\n",
    "\n",
    "            y_id = arc[4 * cell_id + 2]\n",
    "            y_op = arc[4 * cell_id + 3]\n",
    "            y = tf.gather(prev_tensors, y_id) # prev_tensors[y_id]\n",
    "            y = self.get_enas_cell_tf(\n",
    "                cell_id, y_id, NASCellTypeV1.Y_TYPE, y_op,\n",
    "                x, training=training\n",
    "            )\n",
    "\n",
    "            merge_out = x + y\n",
    "            prev_tensors.append(merge_out)\n",
    "\n",
    "            used.extend([\n",
    "                tf.one_hot(x_id, depth=self.num_cells + 2, dtype=tf.int32),\n",
    "                tf.one_hot(y_id, depth=self.num_cells + 2, dtype=tf.int32)\n",
    "            ])\n",
    "        # Select layers (outputs) which are not used for skip connection\n",
    "        used = tf.add_n(used)\n",
    "        indices = tf.where(tf.equal(used, 0))\n",
    "        indices = tf.cast(indices, tf.int32)\n",
    "        indices = tf.reshape(indices, [-1])\n",
    "        num_outs = tf.size(indices)\n",
    "        out = tf.stack(prev_tensors, axis=0)\n",
    "        out = tf.gather(out, indices, axis=0)\n",
    "\n",
    "        out = tf.transpose(out, [1, 2, 3, 0, 4])\n",
    "        shape = tf.shape(out)\n",
    "        out = tf.reshape(out, [shape[0], shape[1], shape[2], num_outs * self.out_filters])\n",
    "\n",
    "        if self.mode == NASModelType.NAS_MODE:\n",
    "            if self.final_module is None:\n",
    "                raise Exception('Final module is not builded but current mode is fixed.')\n",
    "            out = self.final_module(out, indices=indices, training=training)\n",
    "        return out\n",
    "    \n",
    "    def _set_enas_cell(self, module: tf.Module, curr_cell, prev_cell, cell_type, op_id):\n",
    "        self._enas_cells_created_list[curr_cell][cell_type][prev_cell][op_id] = module\n",
    "\n",
    "    def get_enas_cell(self, curr_cell, prev_cell, cell_type, op_id):\n",
    "        # TODO: Call via:\n",
    "        #       https://www.tensorflow.org/api_docs/python/tf/switch_case\n",
    "        #       Should layers be stored as single big vector? Not like right now...\n",
    "        try:\n",
    "            return self._enas_cells_created_list[curr_cell][cell_type][prev_cell][op_id]\n",
    "        except Exception as e:\n",
    "            print(f\"Couldn't get enas-cell by curr_cell={curr_cell}, prev_cell={prev_cell}, cell_type={cell_type}, op_id={op_id}\")\n",
    "            raise e\n",
    "\n",
    "    #@tf.function\n",
    "    def get_enas_cell_tf(\n",
    "            self, curr_cell: int, \n",
    "            prev_cell: tf.Tensor, cell_type: int, \n",
    "            op_id: tf.Tensor, \n",
    "            *args, **kwargs):\n",
    "        # TODO: Call via:\n",
    "        #       https://www.tensorflow.org/api_docs/python/tf/switch_case\n",
    "        #       Should layers be stored as single big vector? Not like right now...\n",
    "        enas_cell_part_list = self._enas_cells_created_list[curr_cell][cell_type]\n",
    "        layer_indx = NASLayer.COUNT_OP * prev_cell + op_id\n",
    "        print(f'Target indx={layer_indx}')\n",
    "\n",
    "        branch_fns_list = []\n",
    "        for prev_cell_i in range(curr_cell+2):\n",
    "            for op_id_i in range(NASLayer.COUNT_OP):\n",
    "                def get_call_layer_fn(prev_cell_i, op_id_i):\n",
    "                    def call_layer_fn():\n",
    "                        print(\n",
    "                            f'Call cell indx={NASLayer.COUNT_OP * prev_cell_i + op_id_i} ' +\\\n",
    "                            f'curr_cell={curr_cell} cell_type={cell_type} '+\\\n",
    "                            f'target[prev_cell={prev_cell} op_id={op_id}] ' +\\\n",
    "                            f'current[prev_cell_i={prev_cell_i} op_id_i={op_id_i}]'\n",
    "                        )\n",
    "                        return enas_cell_part_list[prev_cell_i][op_id_i](*args, **kwargs)\n",
    "                    return call_layer_fn\n",
    "            \n",
    "                branch_fns_list.append(\n",
    "                    (\n",
    "                        NASLayer.COUNT_OP * prev_cell_i + op_id_i, \n",
    "                        get_call_layer_fn(prev_cell_i, op_id_i),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        try:\n",
    "            return tf.switch_case(layer_indx, branch_fns=branch_fns_list)\n",
    "        except Exception as e:\n",
    "            print(f\"Couldn't get enas-cell by curr_cell={curr_cell}, prev_cell={prev_cell}, cell_type={cell_type}, op_id={op_id}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e3ea8aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nas_layer = NASLayer_TEST(\n",
    "    layer_id=3,\n",
    "    arc=None,\n",
    "    out_filters=20, num_cells=5,\n",
    "    input_shape_list=[(1, 32, 32, 20), (1, 16, 16, 20)],\n",
    "    mode=NASModelType.NAS_MODE,\n",
    "    global_step=tf.Variable(0, trainable=False, dtype=tf.int32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d446e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tf.random.uniform((1, 32, 32, 20))\n",
    "t2 = tf.random.uniform((1, 16, 16, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "abafbae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_layers = [t1, t2] \n",
    "arc = tf.convert_to_tensor([0, 0, 0, 1, 2, 0, 2, 1, 2, 1, 3, 1, 3, 1, 4, 1, 3, 1, 0, 1], dtype=tf.int32)\n",
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4c4b9d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorShape([1, 16, 16, 20]), TensorShape([1, 16, 16, 20])]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(prev_layers) == 2 \n",
    "if arc is None and nas_layer.mode == NASModelType.NAS_MODE:\n",
    "    raise Exception(\"Current layer mode is NAS-mode, but arc parameter was not provided to the layer.\")\n",
    "elif arc is None and nas_layer.mode == NASModelType.FIXED_MODE:\n",
    "    arc = self.arc\n",
    "elif arc is not None and nas_layer.mode == NASModelType.FIXED_MODE:\n",
    "    raise Exception(\"Current layer mode is FIXED-mode, but arc parameter was provided to the layer.\")\n",
    "# Answer will be resized two tensors from prev layers\n",
    "x0, x1 = nas_layer.calibrate_size_layer(\n",
    "    *prev_layers, training=training\n",
    ")\n",
    "# TODO: Set size - its known here\n",
    "prev_tensors = [x0, x1]\n",
    "[p.shape for p in prev_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aa44bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "if nas_layer.mode == NASModelType.FIXED_MODE:\n",
    "    if nas_layer.base_module is None:\n",
    "        raise Exception('Base module is not builded but current mode is fixed.')\n",
    "    prev_tensors[-1] = nas_layer.base_module(prev_layers[-1], training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "de94175b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used = []\n",
    "cell_id = 0\n",
    "\n",
    "nas_layer.num_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8113dd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target indx=16\n",
      "Call cell indx=16 curr_cell=3 cell_type=0 target[prev_cell=3 op_id=1] current[prev_cell_i=3 op_id_i=1]\n",
      "Target indx=21\n",
      "Call cell indx=21 curr_cell=3 cell_type=1 target[prev_cell=4 op_id=1] current[prev_cell_i=4 op_id_i=1]\n"
     ]
    }
   ],
   "source": [
    "x_id = arc[4 * cell_id]\n",
    "x_op = arc[4 * cell_id + 1]\n",
    "x = tf.gather(prev_tensors, x_id) # prev_tensors[x_id]\n",
    "x = nas_layer.get_enas_cell_tf(\n",
    "    cell_id, x_id, NASCellTypeV1.X_TYPE, x_op,\n",
    "    x, training=training\n",
    ")\n",
    "\n",
    "\n",
    "y_id = arc[4 * cell_id + 2]\n",
    "y_op = arc[4 * cell_id + 3]\n",
    "y = tf.gather(prev_tensors, y_id) # prev_tensors[y_id]\n",
    "y = nas_layer.get_enas_cell_tf(\n",
    "    cell_id, y_id, NASCellTypeV1.Y_TYPE, y_op,\n",
    "    x, training=training\n",
    ")\n",
    "\n",
    "merge_out = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9792df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_tensors.append(merge_out)\n",
    "\n",
    "used.extend([\n",
    "    tf.one_hot(x_id, depth=nas_layer.num_cells + 2, dtype=tf.int32),\n",
    "    tf.one_hot(y_id, depth=nas_layer.num_cells + 2, dtype=tf.int32)\n",
    "])\n",
    "cell_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c4db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9829760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select layers (outputs) which are not used for skip connection\n",
    "used = tf.add_n(used)\n",
    "indices = tf.where(tf.equal(used, 0))\n",
    "indices = tf.cast(indices, tf.int32)\n",
    "indices = tf.reshape(indices, [-1])\n",
    "num_outs = tf.size(indices)\n",
    "out = tf.stack(prev_tensors, axis=0)\n",
    "out = tf.gather(out, indices, axis=0)\n",
    "\n",
    "out = tf.transpose(out, [1, 2, 3, 0, 4])\n",
    "shape = tf.shape(out)\n",
    "out = tf.reshape(out, [shape[0], shape[1], shape[2], num_outs * self.out_filters])\n",
    "\n",
    "if self.mode == NASModelType.NAS_MODE:\n",
    "    if self.final_module is None:\n",
    "        raise Exception('Final module is not builded but current mode is fixed.')\n",
    "    out = self.final_module(out, indices=indices, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8124a659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f90f0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_layers = [t1, t2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43864fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrate_size_layer = CalibrateTwoLayersSize(\n",
    "    tf.shape(prev_layers[0]), tf.shape(prev_layers[1]), \n",
    "    20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d444a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorShape([1, 16, 16, 20]), TensorShape([1, 16, 16, 20])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in calibrate_size_layer(prev_layers[0], prev_layers[1], training=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2137a84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "93a17338",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_cell = cell_id\n",
    "op_id = x_op\n",
    "cell_type = NASCellTypeV1.X_TYPE\n",
    "prev_cell = x_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4a83a7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=21>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_indx = NASLayer.COUNT_OP * cell_id + op_id\n",
    "layer_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3dd9dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_fns_list = []\n",
    "for prev_cell_i in range(cell_id+2):\n",
    "    for op_id_i in range(NASLayer.COUNT_OP):\n",
    "        def call_layer_fn():\n",
    "            print(\n",
    "                f'Call cell indx={NASLayer.COUNT_OP * prev_cell_i + op_id_i} ' +\\\n",
    "                f'curr_cell={curr_cell} cell_type={cell_type} '+\\\n",
    "                f'target[prev_cell={prev_cell} op_id={op_id}] ' +\\\n",
    "                f'current[prev_cell_i={prev_cell_i} op_id_i={op_id_i}]'\n",
    "            )\n",
    "            return NASLayer.COUNT_OP * prev_cell_i + op_id_i\n",
    "        \n",
    "        def get_call_layer_fn(prev_cell_i, op_id_i):\n",
    "            #prev_cell_i = copy.copy(prev_cell_i)\n",
    "            #op_id_i = copy.copy(op_id_i)\n",
    "            \n",
    "            call_layer_fn = lambda: NASLayer.COUNT_OP * prev_cell_i + op_id_i\n",
    "            \n",
    "            return call_layer_fn\n",
    "        \n",
    "        branch_fns_list.append(\n",
    "            (\n",
    "                NASLayer.COUNT_OP * prev_cell_i + op_id_i, \n",
    "                get_call_layer_fn(prev_cell_i, op_id_i),\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "797a0bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (1, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (2, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (3, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (4, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (5, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (6, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (7, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (8, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (9, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (10, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (11, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (12, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (13, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (14, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (15, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (16, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (17, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (18, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (19, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (20, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (21, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (22, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (23, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (24, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (25, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (26, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (27, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (28, <function __main__.get_call_layer_fn.<locals>.<lambda>()>),\n",
       " (29, <function __main__.get_call_layer_fn.<locals>.<lambda>()>)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_fns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d9e596d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.switch_case(layer_indx, branch_fns=branch_fns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4177b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41f40e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_fns_list = [\n",
    "    lambda: 1,\n",
    "    lambda: 2,\n",
    "    lambda: 3,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e80e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.switch_case(layer_indx, branch_fns=branch_fns_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
