# Implementation of the paper Efficient Neural Architecture Search (ENAS) via Parameter Sharing with TensorFlow 2.x.

For now only Micro search is implemented. Code still in development (or abandoned) due to the complexity of the implementation, so some parts could do not work as intended.

How to use code? Example could be found in the notebook [`train_jup.ipynb`](./train_jup.ipynb).
In notebook [`train_jup_debug.ipynb`](./train_jup_debug.ipynb) training comes with additional debug stuff, but in most cases its only for development.

Re-implementation of the paper about ENAS with TF 2.x. Most of the code taken from [original repo](https://github.com/melodyguan/enas), which written on TF 1.X.

Also other re-implemetatnions on torch:
- [ENAS-pytorch](https://github.com/carpedm20/ENAS-pytorch)
- [enas-pytorch](https://github.com/MengTianjian/enas-pytorch)